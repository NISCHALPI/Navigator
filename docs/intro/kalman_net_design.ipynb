{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Design for Single Differenced Kalman Network for GNSS Triangulation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we design a Recurrent Neural Network (RNN) aided kalman filter for GPS/GNSS triangulation. The main motivation behind this is that this is able to learn the non-linear filter for a given reciever and satellite constellation and the reciever dependent noise characteristics. \n",
    "\n",
    "The main paper that we are following:\n",
    "\n",
    "- [KalmanNet: Neural Network Aided Kalman Filtering for Partially Known Dynamics](https://ieeexplore.ieee.org/abstract/document/9733186?casa_token=E7Dlt41RuYMAAAAA:K_hc0gJoRDXLG3BNt6tS3QW1Tzf54jufij9adE7HcjGst0VeyXWhWe5Mc1MiyXH7tY_gcH0GNg)\n",
    "\n",
    "\n",
    "This architecture has shown performance improvements over the traditional Kalman Filter (KF), Extended Kalman Filter (EKF), and Unscented Kalman Filter (UKF) in the case of non-linear dynamics and unknown noise characteristics as well as unknown dynamics. The main idea is to use a RNN to learn the dynamics and the noise characteristics of the system. Rather than tracking second order statistics of the system, we let the RNN learn the second order statistics of the system.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Problem Formulation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GPS/GNSS problem is a non-linear problem. The measurement model in the non-linear observation equations. The dynamics, for example, the position of the moving object, is also generally non-linear. Hence, the traditional KF is not applicable. The EKF and UKF are applicable, but they require the knowledge of the noise characteristics of the system. This is not always available or easy to obtain. However, the RNN can learn the noise characteristics of the given system using the labeled data.\n",
    "\n",
    "The state space model for the GPS/GNSS problem is genrally given as:\n",
    "$$\n",
    "x = \\begin{bmatrix} x \\\\ y \\\\ z \\\\ \\dot{x} \\\\ \\dot{y} \\\\ \\dot{z} \\\\ cdt \\\\ c\\dot{dt}\\end{bmatrix}\n",
    "$$\n",
    "where $x,y,z$ are the position of the reciever in the ECEF frame, $\\dot{x},\\dot{y},\\dot{z}$ are the velocity of the reciever in the ECEF frame, $cdt$ is the clock bias of the reciever, and $c\\dot{dt}$ is the clock drift of the reciever with respect to the GPS/GNSS time.\n",
    "\n",
    "The pseudorange equation is given as:\n",
    "$$\n",
    "\\rho = \\sqrt{(x-x_s)^2 + (y-y_s)^2 + (z-z_s)^2} + cdt + \\epsilon\n",
    "$$\n",
    "where $x_s,y_s,z_s$ are the position of the satellite in the ECEF frame, and $\\epsilon$ is the noise in the measurement.\n",
    "\n",
    "These were the assumption made in the [UKF Aided Kalman Filter](unscented_kalman_filter_gps.ipynb) notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Architecture Design Problem** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are few design problems that we need to solve before we can implement the KalmanNet.\n",
    "\n",
    "1. How does the training data look like?  \n",
    "    Just like any neural network, training data will contaion an input X and a labelled output Y. Since the base architecture of the Kalman Net is RNN, the input will be time series of the observables,\n",
    "    $$\n",
    "    P_i = \\begin{bmatrix} \\rho_{1,i} \\\\ \\rho_{2,i} \\\\ \\vdots \\\\ \\rho_{N_s,i} \\end{bmatrix}\n",
    "    $$\n",
    "    where $i$ is the time index, and $N_s$ is the number of satellites in view. The labelled training data Y will be the time series of position and velocity of the reciever in the ECEF frame.\n",
    "    $$\n",
    "    Y_i = \\begin{bmatrix} x_i \\\\ y_i \\\\ z_i \\\\ \\dot{x}_i \\\\ \\dot{y}_i \\\\ \\dot{z}_i \\end{bmatrix}\n",
    "    $$\n",
    "\n",
    "    **Note: Prior to the training, user can correct the data for modeled errors such as ionospheric delay, tropospheric delay, and satellite clock bias. This further improves the performance of the KalmanNet because it will be trained on more precise data.**\n",
    "\n",
    "\n",
    "2. What about the reciever clock bias and drift?  \n",
    "    The reciever clock bias and drift are not observables since they are very hard to measure with high accuracy and are generally noisy. So, they are not included in the training data. So, we will have to simultaneously eliminate them and gain some advantage doing that. This is done by using the single differenced measurement model. The single differenced measurement mode. Hence out state space model becomes:\n",
    "    $$\n",
    "    x = \\begin{bmatrix} x \\\\ y \\\\ z \\\\ \\dot{x} \\\\ \\dot{y} \\\\ \\dot{z} \\end{bmatrix}\n",
    "    $$\n",
    "    Hence, the clock bias is not calculated. This can be calculated using least squares or UKF. Eliminating the clock bias, we have more gain more precision in the location estimation and velocity estimation which are the main goals of the GPS/GNSS problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Single Differenced Equations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To eliminate the reciever clock bias, we use the single differenced measurement model. This measurement model is given as:\n",
    "$$\n",
    "\\rho_{ij} = \\rho_{i} - \\rho_{j} + \\epsilon_{ij}\n",
    "$$\n",
    "where $\\rho_{ij}$ is the single differenced pseudorange between the $i^{th}$ and $j^{th}$ reference satellite, $\\rho_{i}$ is the pseudorange of the $i^{th}$ reference satellite, $\\rho_{j}$ is the pseudorange of the $j^{th}$ reference satellite, and $\\epsilon_{ij}$ is the remaining noise in the single differenced pseudorange.\n",
    "\n",
    "Since the reciever clock bias is same for all the satellites at a given time, the pseudorange equation for the $i^{th}$ satellite is given as:\n",
    "$$\n",
    "\\rho_{i} = \\sqrt{(x-x_i)^2 + (y-y_i)^2 + (z-z_i)^2} + cdt + \\epsilon_i\n",
    "$$\n",
    "where $x_i,y_i,z_i$ are the position of the $i^{th}$ satellite in the ECEF frame, and $\\epsilon_i$ is the noise in the measurement. Now a reference satellite is chosen, generally having the highest elevation angle as the reference satellite. The single differenced pseudorange equation for the $i^{th}$ and $j^{th}$ satellite is given as:\n",
    "$$\n",
    "\\rho_{ij} = \\sqrt{(x-x_i)^2 + (y-y_i)^2 + (z-z_i)^2} - \\sqrt{(x-x_j)^2 + (y-y_j)^2 + (z-z_j)^2} + cdt - cdt + \\epsilon_{i} - \\epsilon_{j}\n",
    "$$\n",
    "The clock bias is eliminated. The single differenced pseudorange equation for the $i^{th}$ and $j^{th}$ satellite is given as:\n",
    "$$\n",
    "\\rho_{ij} = \\sqrt{(x-x_i)^2 + (y-y_i)^2 + (z-z_i)^2} - \\sqrt{(x-x_j)^2 + (y-y_j)^2 + (z-z_j)^2} + \\epsilon_{ij}\n",
    "$$\n",
    "where $\\epsilon_{ij} = \\epsilon_{i} - \\epsilon_{j}$ is the remaining noise in the single differenced pseudorange.\n",
    "\n",
    "We will feed the KalmanNet with the single differenced pseudorange measurements and the KalmanNet will output the position and velocity of the reciever in the ECEF frame. This requires that at least 4 satellites are in view of the reciever.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **State Transistion and Measurement Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **State Transition Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The constant velocity model is used for the state transistion model as in the [UKF Aided Kalman Filter](unscented_kalman_filter_gps.ipynb) notebook. The state transistion model matrix is given as:\n",
    "$$\n",
    "A = \\begin{bmatrix} 1 & \\Delta t \\\\ 0 & 1 \\end{bmatrix}\n",
    "$$\n",
    "Now the state transition function can be calculated as:\n",
    "$$\n",
    "F = \\begin{bmatrix} A & 0 & 0 & 0 \\\\ 0 & A & 0 & 0 \\\\ 0 & 0 & A & 0 \\end{bmatrix}\n",
    "$$\n",
    "where $A$  is constant velocity model matrix, and $\\Delta$ is the time step for the measurement update which depends on the sampling rate of the GPS/GNSS reciever. \n",
    "\n",
    "For the Kalman Net, the process noise is modelled by the RNN. Hence, the model mismatch can be mitigated, and noise characteristics can be directly learned from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of the State Transition Matrix for Kalman Net\n",
    "import numpy as np\n",
    "import numba as nb\n",
    "\n",
    "nb.njit(\n",
    "    nb.float64[:,:](nb.float64[:], nb.float64),\n",
    "    fastmath=True,\n",
    "    cache=True,\n",
    "    parallel=True\n",
    ")\n",
    "def fx(x : np.ndarray, dt : float) -> np.ndarray:\n",
    "    \"\"\"State transition function for the Single Differential Kalman Net.\n",
    "    Args:\n",
    "        x (ndarray): Current state vector. Shape (6) 1D array.\n",
    "        dt (float): Time step. Units: seconds.\n",
    "    \n",
    "    Returns:\n",
    "        ndarray: Time translated state vector.\n",
    "    \"\"\"\n",
    "    # Unit evolution matrix\n",
    "    A = np.eye(2, dtype=np.float64)\n",
    "    A[0,1] = dt\n",
    "\n",
    "    # State transition function 6 * 4 constant velocity model\n",
    "    F = np.kron(np.eye(3, dtype=np.float64), A)\n",
    "\n",
    "    return F @ x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Measurement Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The measurement function as discussed above is the SD-Measurement model. Let $j$ denote the reference satellite, and $s$ denote the current state, $ik$ denote the observed $k$ satellites . The measurement function $h(x_s, y_s, z_s,)$ is given as:\n",
    "$$\n",
    "h(x_s, y_s, z_s, \\vec{X_{ik}}, \\vec{X_{rf}}) = \\sqrt{(x_s-x_{ik})^2 + (y_s-y_{ik})^2 + (z_s-z_{ik})^2} - \\sqrt{(x_s-x_{j})^2 + (y_s-y_{j})^2 + (z_s-z_{j})^2}\n",
    "$$\n",
    "where $x_s,y_s,z_s$ are current state of the reciever in the ECEF frame, $\\vec{X_{ik}}$ is the vector of the position of the $k$ satellites in the ECEF frame, and $\\vec{X_{rf}}$ is the vector of the position of the reference satellite in the ECEF frame.\n",
    "\n",
    "Hence, the follwing argumente are required for the measurement function:\n",
    "- The current state of the reciever in the ECEF frame (As is the convention in the Kalman Filter)\n",
    "- The position of the reference satellite in the ECEF frame(To eliminate the clock bias)\n",
    "- The position of the satellites in the ECEF frame (To calculate the differenced pseudorange which are the observables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of the measurement function for the Kalman Net\n",
    "nb.njit(\n",
    "    nb.float64[:](nb.float64[:], nb.float64[:,:], nb.float64[:]),\n",
    "    fastmath=True,\n",
    "    cache=True,\n",
    "    parallel=True\n",
    ")\n",
    "def hx(x : np.ndarray, sv_matrix : np.ndarray , reference_sv : np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Measurement function for the Single Differential Kalman Net.\n",
    "    Args:\n",
    "        x (ndarray): Current state vector. Shape (6,) 1D array.\n",
    "        sv_matrix (ndarray): Satellite state vector matrix. Shape (n, 3). n = number of satellites.\n",
    "        reference_sv (ndarray): Reference satellite state vector. Shape (3) 1D array.\n",
    "    \n",
    "    Returns:\n",
    "        ndarray: Differenced pseduorange measurement vector. Shape (n,) 1D array.\n",
    "    \"\"\"\n",
    "    # Assert that the input is of the correct shape\n",
    "    assert x.shape == (6,), f\"Shape of state is {x.shape}\"\n",
    "    assert sv_matrix.shape[1] == 3 , f\"Shape of sv_matrix is {sv_matrix.shape}\"\n",
    "    assert reference_sv.shape == (3,) , f\"Shape of reference_sv is {reference_sv.shape}\"\n",
    "\n",
    "    # Single differential pseudorange measurement function\n",
    "    return np.linalg.norm(x[:3] - sv_matrix, axis=1) - np.linalg.norm(x[:3] - reference_sv)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **KalmanNet Architecture**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the paper, the KalmanNet architecture is similar to the EKF architecture. First an abstract class is defined for the KalmanNet. This class contatins abstract methods that need to be implemented by the child class. These methods will be choosen based on the specific architecture of the KalmanNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from assertpy import assert_that\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "\n",
    "class AbstractKalmanNet(ABC):\n",
    "    \"\"\"The Kalman Net abstract base class.\n",
    "\n",
    "    Args:\n",
    "        ABC (_type_): Abstract base class.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                dim_state : int, \n",
    "                dim_measurement : int, \n",
    "                dt : float,\n",
    "                flavor : list[str] | None = None, \n",
    "                **kwargs):\n",
    "        \"\"\"Initializes the Kalman Net.\n",
    "\n",
    "        Args:\n",
    "            dim_state (int): Dimension of the state vector.\n",
    "            dim_measurement (int): Dimension of the measurement vector.\n",
    "            dt (float): Time steps of measurements. Units: seconds.\n",
    "            flavor (list[str], optional): List of the combination flavors to be used for calculating the kalman gain. Defaults to [\"F1\", \"F2\", \"F4\"].\n",
    "            **kwargs: Keyword arguments for the stack initialization.\n",
    "        \n",
    "        Optional Keyword Args:\n",
    "            posterior_stack_size (int): Size of the posterior stack, should be greater that >=2. Default: 10.\n",
    "            prior_stack_size (int): Size of the prior stack. Default: 10.\n",
    "            measurement_history_size (int): Size of the measurement history stack. Default: 2.\n",
    "            x0 (ndarray): Initial state vector. Shape (dim_state,) 1D array. Default: np.zeros(dim_state).\n",
    "            y0 (ndarray): Initial measurement vector. Shape (dim_measurement,) 1D array. Default: np.zeros(dim_measurement).\n",
    "\n",
    "        Raises:\n",
    "            AssertionError: If the dimensions are not greater than 0.\n",
    "            AssertionError: If the time step is not greater than 0.\n",
    "            AssertionError: If the flavor is not a list.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \n",
    "        \"\"\"\n",
    "        # Initialize the dimensions\n",
    "        self.x_dim = dim_state if assert_that(dim_state).is_type_of(int).is_greater_than(0) else None\n",
    "        self.y_dim = dim_measurement if assert_that(dim_measurement).is_type_of(int).is_greater_than(0) else None\n",
    "\n",
    "        # Initialize the time step\n",
    "        self.dt = dt if assert_that(dt).is_type_of(float).is_greater_than(0) else None\n",
    "\n",
    "        # Initialize the posterior stack \n",
    "        self.x_posterior_stack = deque(maxlen=kwargs.get(\"posterior_stack_size\", 10))\n",
    "        self.P_posterior_stack = deque(maxlen=kwargs.get(\"posterior_stack_size\", 10))\n",
    "\n",
    "        # Initialize the prior stack\n",
    "        self.x_prior_stack = deque(maxlen=kwargs.get(\"prior_stack_size\", 10))\n",
    "        self.P_prior_queue = deque(maxlen=kwargs.get(\"prior_stack_size\", 10))\n",
    "\n",
    "        # Predicted measurement stack\n",
    "        self.y_stack = deque(maxlen=kwargs.get(\"measurement_history_size\", 2))\n",
    "        self.y_hat_stack = deque(maxlen=kwargs.get(\"measurement_history_size\", 2))\n",
    "\n",
    "        # Check if the flavor is a list\n",
    "        if flavor is None:\n",
    "            flavor = [\"F1\", \"F2\", \"F4\"]\n",
    "        self.flavor = flavor if assert_that(flavor).is_type_of(list).contains_only(\"F1\", \"F2\", \"F3\", \"F4\") else [\"F1\", \"F2\", \"F4\"]\n",
    "        \n",
    "        # Initialize the stacks appropriately\n",
    "        self._stack_init(**kwargs)\n",
    "\n",
    "\n",
    "    def _stack_init(self, **kwargs) -> None:\n",
    "        \"\"\"This function initializes the stacks inplace according to the paper.\n",
    "        \n",
    "        Args:\n",
    "            **kwargs: Keyword arguments for the stack initialization.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        # Initialize the initial value for the posterior stack\n",
    "        self.x_posterior_stack.append(kwargs.get(\"x0\", np.zeros(self.x_dim)))\n",
    "        # Needs to be initialize twice since two posterior values are needed for the F3 combination at t=1\n",
    "        self.x_posterior_stack.append(kwargs.get(\"x0\", np.zeros(self.x_dim)))\n",
    "        \n",
    "        #Note : P_posterior needn't be initialized since it is calculated from RNN and RNN weights are initialized randomly!\n",
    "        \n",
    "        # Initialize the measuremet stack with the initial measurement\n",
    "        # This is needed for the F1 combination at t=1 since it uses previous measurement (y_{t-1})\n",
    "        self.y_meas_prev = kwargs.get(\"y0\", np.zeros(self.y_dim)) \n",
    "\n",
    "        # No need to initialize the y_hat stack since it is calculated from \n",
    "        # x_prior for t=1 and y_1 is provided by the user\n",
    "\n",
    "        # For the combination F4, the prior needs to be initialized since\n",
    "        # at t=1, the combination four used x_{t-1}_posterior and x_{t-1}_prior\n",
    "        self.x_prior = kwargs.get(\"x0\", np.zeros(self.x_dim))\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "    @property\n",
    "    def x_posterior(self) -> np.ndarray:\n",
    "        \"\"\"Returns the current posterior state vector.\n",
    "\n",
    "        Returns:\n",
    "            ndarray: Current posterior state vector. Shape (dim_state,) 1D array.\n",
    "        \"\"\"\n",
    "        return self.x_posterior_stack[-1]\n",
    "    \n",
    "    @x_posterior.setter\n",
    "    def x_posterior(self, x : np.ndarray) -> None:\n",
    "        \"\"\"Sets the current posterior state vector.\n",
    "\n",
    "        Args:\n",
    "            x (ndarray): Current posterior state vector. Shape (dim_state,) 1D array.\n",
    "        \"\"\"\n",
    "        self.x_posterior_stack.append(x)\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def P_posterior(self) -> np.ndarray:\n",
    "        \"\"\"Returns the current posterior covariance matrix.\n",
    "\n",
    "        Returns:\n",
    "            ndarray: Current posterior covariance matrix. Shape (dim_state, dim_state) 2D array.\n",
    "        \"\"\"\n",
    "        return self.P_posterior_stack[-1]\n",
    "    \n",
    "    @P_posterior.setter\n",
    "    def P_posterior(self, P : np.ndarray) -> None:\n",
    "        \"\"\"Sets the current posterior covariance matrix.\n",
    "\n",
    "        Args:\n",
    "            P (ndarray): Current posterior covariance matrix. Shape (dim_state, dim_state) 2D array.\n",
    "        \"\"\"\n",
    "        self.P_posterior_stack.append(P)\n",
    "    \n",
    "    @property\n",
    "    def x_prior(self) -> np.ndarray:\n",
    "        \"\"\"Returns the current prior state vector.\n",
    "\n",
    "        Returns:\n",
    "            ndarray: Current prior state vector. Shape (dim_state,) 1D array.\n",
    "        \"\"\"\n",
    "        return self.x_prior_stack[-1]\n",
    "    \n",
    "    @x_prior.setter\n",
    "    def x_prior(self, x : np.ndarray) -> None:\n",
    "        \"\"\"Sets the current prior state vector.\n",
    "\n",
    "        Args:\n",
    "            x (ndarray): Current prior state vector. Shape (dim_state,) 1D array.\n",
    "        \"\"\"\n",
    "        self.x_prior_stack.append(x)\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def P_prior(self) -> np.ndarray:\n",
    "        \"\"\"Returns the current prior covariance matrix.\n",
    "\n",
    "        Returns:\n",
    "            ndarray: Current prior covariance matrix. Shape (dim_state, dim_state) 2D array.\n",
    "        \"\"\"\n",
    "        return self.P_prior_queue[-1]\n",
    "    \n",
    "    @P_prior.setter\n",
    "    def P_prior(self, P : np.ndarray) -> None:\n",
    "        \"\"\"Sets the current prior covariance matrix.\n",
    "\n",
    "        Args:\n",
    "            P (ndarray): Current prior covariance matrix. Shape (dim_state, dim_state) 2D array.\n",
    "        \"\"\"\n",
    "        self.P_prior_queue.append(P)\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def y_hat(self) -> np.ndarray:\n",
    "        \"\"\"Returns the current predicted measurement vector.\n",
    "\n",
    "        Returns:\n",
    "            ndarray: Current predicted measurement vector. Shape (dim_measurement,) 1D array.\n",
    "        \"\"\"\n",
    "        return self.y_hat_stack[-1]\n",
    "    \n",
    "    @y_hat.setter\n",
    "    def y_hat(self, y : np.ndarray) -> None:\n",
    "        \"\"\"Sets the current predicted measurement vector.\n",
    "\n",
    "        Args:\n",
    "            y (ndarray): Current predicted measurement vector. Shape (dim_measurement,) 1D array.\n",
    "        \"\"\"\n",
    "        self.y_hat_stack.append(y)\n",
    "\n",
    "    @property\n",
    "    def y_meas_prev(self) -> np.ndarray:\n",
    "        \"\"\"Returns the previous measurement vector.\n",
    "\n",
    "        Returns:\n",
    "            ndarray: Current measurement vector. Shape (dim_measurement,) 1D array.\n",
    "        \"\"\"\n",
    "        return self.y_stack[-1]\n",
    "    \n",
    "    @y_meas_prev.setter\n",
    "    def y_meas_prev(self, y : np.ndarray) -> None:\n",
    "        \"\"\"Sets the current measurement vecto to the previous measurement vector.\n",
    "\n",
    "        Args:\n",
    "            y (ndarray): Current measurement vector. Shape (dim_measurement,) 1D array.\n",
    "        \"\"\"\n",
    "        self.y_stack.append(y)\n",
    "\n",
    "    @abstractmethod\n",
    "    def fx(self, x : np.ndarray, *args , **kwargs) -> np.ndarray:\n",
    "        \"\"\"State transition function. This function is implemented by the child class.\n",
    "\n",
    "        Args:\n",
    "            x (ndarray): Current state vector. Shape (dim_state,) 1D array.\n",
    "\n",
    "        Returns:\n",
    "            ndarray: Time translated state vector. Shape (dim_state,) 1D array.\n",
    "        \"\"\"\n",
    "       \n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def hx(self, x : np.ndarray, *args , **kwargs) -> np.ndarray:\n",
    "        \"\"\"Measurement function. This function is implemented by the child class.\n",
    "\n",
    "        Args:\n",
    "            x (ndarray): Current state vector. Shape (dim_state,) 1D array.\n",
    "\n",
    "        Returns:\n",
    "            ndarray: Measurement vector. Shape (dim_measurement,) 1D array.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def F1(y_t : np.ndarray, y_prev_mes : np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Calculates the F1 combination (observation difference) for feeding to RNN layer.\n",
    "        \n",
    "        This combination encapsulates the physics state evolution process since this uses only the \n",
    "        measurements of the current and previous time step. \n",
    "\n",
    "\n",
    "        Args:\n",
    "            y_t (ndarray): Current measurement vector. Shape (dim_measurement,) 1D array.\n",
    "            y_prev_mes (ndarray): Previous measurement vector. Shape (dim_measurement,) 1D array.\n",
    "\n",
    "        Returns:\n",
    "            ndarray: F1 combination. (dim_measurement)\n",
    "        \"\"\"\n",
    "        return y_t - y_prev_mes\n",
    "\n",
    "    @staticmethod\n",
    "    def F2(self, y_t : np.ndarray, y_hat : np.ndarray) -> np.ndarray: \n",
    "        \"\"\"This calculates the F2 combination (innovation difference) for feeding to RNN layer.\n",
    "\n",
    "        This combination encapsulates the uncertainty of state estimation process since this uses the\n",
    "        measurement and predicted measurement of the current time step.\n",
    "\n",
    "        Args:\n",
    "            y_t (ndarray): Current measurement vector. Shape (dim_measurement,) 1D array.\n",
    "            y_hat (ndarray): Predicted measurement vector. Shape (dim_measurement,) 1D array.\n",
    "\n",
    "        Returns:\n",
    "            ndarray: F2 combination. (dim_measurement)\n",
    "        \"\"\" \n",
    "        return y_t - y_hat\n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def F3(self, x_t11 : np.ndarray, x_t00) -> np.ndarray:\n",
    "        \"\"\"This calculates the F3 combination (forward evolution difference) for feeding to RNN layer.\n",
    "\n",
    "        This combination encapsulates the state evolution process since this uses the state vectors of two consecutive posterior\n",
    "        state vectors. This is taken for t-1 for time step t.\n",
    "\n",
    "        Args:\n",
    "            x_t11 (ndarray): Current previous vector. Shape (dim_state,) 1D array.\n",
    "            x_t00 (ndarray): Previous state vector. Shape (dim_state,) 1D array.\n",
    "\n",
    "        Returns:\n",
    "            ndarray: F3 combination. (dim_state)\n",
    "        \"\"\"\n",
    "        return x_t11 - x_t00\n",
    "    \n",
    "    @staticmethod\n",
    "    def F4(self, x_t11 : np.ndarray, x_t00: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"This calculates the F4 combination (forward update difference) for feeding to RNN layer.\n",
    "\n",
    "        This combination encapsulates the uncertainty of state evolution process since this uses the state vectors of prior state estimates\n",
    "        . This is taken for t-1 for time step t.\n",
    "\n",
    "        Args:\n",
    "            x_t11 (ndarray): Current posterior vector. Shape (dim_state,) 1D array.\n",
    "            x_t00 (ndarray): Current prior vector. Shape (dim_state,) 1D array.\n",
    "\n",
    "        Returns:\n",
    "            ndarray: F4 combination. (dim_state)\n",
    "        \"\"\"\n",
    "        return x_t11 - x_t00\n",
    "    \n",
    "    \n",
    "    def predict(self, **kwargs) -> None:\n",
    "        \"\"\"Predicts the x_t|t-1 using the state transition function.\n",
    "\n",
    "        The state transition function is implemented by the child class.The values are stored in the x_prior attribute. The KalmanNet does not track second-order statistics. \n",
    "        Please refer to the paper for more details.\n",
    "\n",
    "        Paper: \n",
    "            KalmanNet: Neural Network Aided Kalman Filtering for Partially Known Dynamics\n",
    "            <https://ieeexplore.ieee.org/abstract/document/9733186?casa_token=E7Dlt41RuYMAAAAA:K_hc0gJoRDXLG3BNt6tS3QW1Tzf54jufij9adE7HcjGst0VeyXWhWe5Mc1MiyXH7tY_gcH0GNg>\n",
    "\n",
    "        Args:\n",
    "            **kwargs: Keyword arguments for the state transition function.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "    \"\"\"\n",
    "        # Get the current posterior\n",
    "        x_t00 = self.x_posterior\n",
    "        # Pass the current posterior to the state transition function\n",
    "        x_t10 = self.fx(x_t00, **kwargs)\n",
    "\n",
    "        # Set the prior\n",
    "        self.x_prior = x_t10\n",
    "\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def update(self, y : np.ndarray, **kwargs) -> None:\n",
    "        \"\"\"This is the update loop of the Kalman Net.\n",
    "\n",
    "        The update loop of the Kalman Net calculates the x_t|t and P_t|t (from Neural Net) from the x_t|t-1 (stored in the x_prior attribute).\n",
    "        The updated values are stored in the most recent x_posterior and P_posterior attributes.\n",
    "\n",
    "        Args:\n",
    "            y (np.ndarray): Measurement vector. Shape (dim_measurement,) 1D array.\n",
    "            **kwargs: Keyword arguments for the measurement function.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        # Get the current prior\n",
    "        x_t10 =  self.x_prior\n",
    "\n",
    "        # Pass the current prior to the measurement function to get y_hat\n",
    "        y_hat = self.hx(x_t10, **kwargs)\n",
    "        # Set the predicted measurement to the y_hat attribute\n",
    "        self.y_hat = y_hat\n",
    "\n",
    "        # Calculate the flavor combinations\n",
    "        combinations = {\n",
    "            \"F1\" : self.F1(y, self.y_meas_prev),\n",
    "            \"F2\" : self.F2(y, y_hat), # This is the innovation difference\n",
    "            \"F3\" : self.F3(self.x_posterior, self.x_posterior_stack[-2]), # Use t-1 and t-2 posterior\n",
    "            \"F4\" : self.F4(self.x_posterior, self.x_prior_stack[-2]) # Use t-1 posterior and t-1 prior\n",
    "        }\n",
    "\n",
    "        # Calculate the kalman gain\n",
    "        kalman_gain = self.forward(combinations)\n",
    "\n",
    "        # Update the posterior\n",
    "        self.x_posterior = x_t10 + kalman_gain @ combinations[\"F2\"]\n",
    "\n",
    "        return\n",
    "    \n",
    "    @abstractmethod\n",
    "    def forward(self, combination : dict) -> np.ndarray:\n",
    "        \"\"\"The forward pass of the Kalman Net.\n",
    "\n",
    "        This function takes in the combination dictionary and calculates the forward pass of the Kalman Net.\n",
    "        Must be implemented by the child class using Neural Net.\n",
    "\n",
    "        Args:\n",
    "            combination (dict): Dictionary of the combination flavors and their values.\n",
    "\n",
    "        Returns:\n",
    "            ndarray: The kalman gain matrix. Shape (dim_state, dim_measurement) 2D array.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "navigator-tJ-eCaO9-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
